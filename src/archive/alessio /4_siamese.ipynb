{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Pre-workout",
   "metadata": {
    "cell_id": "66fbd74bcefa4a0689444c2252d48157",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Import ",
   "metadata": {
    "cell_id": "48103ec1004f4ef281e8e177dab00321",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0fdeb858a38d4ea1b3f2f29678e31712",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e63fe702",
    "execution_start": 1651154398683,
    "execution_millis": 5979,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 173.4375
   },
   "source": "!pip3 install opencv-python-headless # questo funziona a differenze dell import classico",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: opencv-python-headless in /root/venv/lib/python3.7/site-packages (4.5.5.64)\nRequirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /shared-libs/python3.7/py/lib/python3.7/site-packages (from opencv-python-headless) (1.21.6)\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "b65c5449e4794501915b3e2694c17566",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "daf33abe",
    "execution_start": 1651154404670,
    "execution_millis": 10779,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 369.15625
   },
   "source": "\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow as tf\nimport cv2 \nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Lambda\nimport tensorflow.keras.backend as K",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Classes and functions",
   "metadata": {
    "cell_id": "b644050e59754220bbedbf7e514477ff",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Dataset Class",
   "metadata": {
    "cell_id": "1852b0ad6eff462fa3ad8c55676b0f82",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a9290a4c06c04661afd4c193617fc517",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "55680bc",
    "execution_start": 1651154415474,
    "execution_millis": 16,
    "is_code_hidden": false,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1251.15625
   },
   "source": "class Dataset(object):\n    def __init__(self, data_path):\n        #path of the dataset\n        self.data_path = data_path\n\n        #class list\n        self.data_classes = [directory for directory in os.listdir(data_path) if os.path.isdir(data_path+directory)]\n\n        # init lists and dictionary\n        self.images = []\n        self.labels = []\n        self.class_names = {}\n\n        # for each class and for each image save the image and the label in the lists \n        for c, c_name in enumerate(self.data_classes):\n            temp_path = os.path.join(self.data_path, c_name)\n            temp_images = os.listdir(temp_path)\n            self.class_names[c] = c_name\n\n            for i in temp_images:\n                img_tmp = os.path.join(temp_path, i)\n\n\n                if img_tmp.endswith('.jpg') or img_tmp.endswith('.JPEG'):\n                   # img = image.load_img(img_tmp, target_size=(224,224))\n                    img = cv2.imread(img_tmp, 3)\n                    model_image_size = (128, 128)\n                    resized_image = cv2.resize(img, model_image_size, interpolation = cv2.INTER_CUBIC)\n                    resized_image = resized_image.astype(np.float32) / 255.0\n                    self.images.append(resized_image)\n                    self.labels.append(c)\n                    \n\n        print('Loaded {:d} images from {:s} '.format(len(self.images), self.data_path))\n\n\n\n    def num_classes(self):\n        # returns number of classes of the dataset\n        return len(self.data_classes)\n    \n    def get_dataset(self):\n        return (list(zip(self.images, self.labels)), self.class_names)\n\n    def generate(self):\n\n        datagen = ImageDataGenerator(\n            rotation_range=10, # rotation\n            width_shift_range=0.2, # horizontal shift\n            height_shift_range=0.2, # vertical shift\n            zoom_range=0.2, # zoom\n            horizontal_flip=True, # horizontal flip\n            brightness_range=[0.2,1.2]\n            ) # brightness\n\n        train_generator = datagen.flow_from_directory(\n                  directory=self.data_path,\n                  target_size=(128, 128), # resize to this size\n                  color_mode=\"rgb\", # for coloured images\n                  batch_size=32, # number of images to extract from folder for every batch\n                  #class_mode=\"binary\", # classes to predict\n                  seed=420 # to make the result reproducible\n                  )\n\n\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### make pairs fun",
   "metadata": {
    "cell_id": "66e09554fc2a4356b744f4c6f175b641",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h3"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "038fab90163346529214c4dde762a6c6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cbeac5da",
    "execution_start": 1651154415498,
    "execution_millis": 616263,
    "is_code_hidden": false,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 945.171875
   },
   "source": "def get_random_image_idx_same_class(dataset, classe):\n\n    label = 'formaggio'\n\n    while label != classe:\n        idx = np.random.choice(len(dataset))\n        label = dataset[idx][1]\n    \n    return idx\n\ndef get_random_image_idx_different_class(dataset, classe):\n\n    label = classe\n\n    while label == classe:\n        idx = np.random.choice(len(dataset))\n        label = dataset[idx][1]\n    \n    return idx\n\n\ndef make_pairs(dataset):\n    # initialize two empty lists to hold the (image, image) pairs and\n    # labels to indicate if a pair is positive or negative\n    pairImages = []\n    pairLabels = []\n    imgs, labels = list(zip(*dataset))\n    numClasses = len(np.unique(labels))\n\n    for img, label in dataset:\n        #current image \n        currentImage = img\n        label = label \n\n        #positive image \n        pos_idx = get_random_image_idx_same_class(dataset, label)\n        pos_img = imgs[pos_idx]\n\n        pairImages.append([currentImage, pos_img])\n        pairLabels.append([1])\n\n        #negative imahe\n        neg_idx = get_random_image_idx_different_class(dataset, label)\n        neg_img = imgs[neg_idx]\n\n        pairImages.append([currentImage, neg_img])\n        pairLabels.append([0])\n\n    return (np.array(pairImages), np.array(pairLabels))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a25271c030e646248f16481bac2c7417",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9b8330",
    "execution_start": 1651154415504,
    "execution_millis": 616256,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 495.171875
   },
   "source": "def make_pairs_efficient(dataset):\n     # initialize two empty lists to hold the (image, image) pairs and\n    # labels to indicate if a pair is positive or negative\n    pairImages = []\n    pairLabels = []\n\n    for idx, (img, label) in enumerate(dataset):\n  \n        \n        #positive image \n        pos_idx = get_random_image_idx_same_class(dataset, label)\n        \n\n        pairImages.append([idx, pos_idx])\n        pairLabels.append([1])\n\n        #negative imahe\n        neg_idx = get_random_image_idx_different_class(dataset, label)\n        \n\n        pairImages.append([idx, neg_idx])\n        pairLabels.append([0])\n\n    return (np.array(pairImages), np.array(pairLabels))",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Dataset",
   "metadata": {
    "cell_id": "6d90b893c9c646d5adde5d886edecdfd",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "training is a list of tuple (image, label),  class_names is a dictionary : class_names[3] = struzzo",
   "metadata": {
    "cell_id": "59116c86b00646f58fa2ce4cc0fa0dc1",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "d9ce96532aec48669e7ef36ae1dce4c5",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "751eb227",
    "execution_start": 1651154415510,
    "execution_millis": 28404,
    "owner_user_id": "4ffd0e12-c633-4f4a-8a0a-9942ba78ed45",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 238.625
   },
   "source": "#training_path = '/datasets/animali/animals_dataset_the_ostriches/unbalanced_dataset_2304/training/'\nvalidation_path = '/work/dataset/validation/gallery/'\ntraining_path = '/work/dataset/training/'\n\ntraining, class_names = Dataset(data_path = training_path).get_dataset()\nvalidation, class_names_val = Dataset(data_path = validation_path).get_dataset()\n",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Loaded 2174 images from /work/dataset/training/ \nLoaded 463 images from /work/dataset/validation/gallery/ \n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "pairTrain is a tuple with 2 images, labelTrain is 0 is the two images belong to 2 different classes 1 if are the same animal",
   "metadata": {
    "cell_id": "a47795ef387f48aa85ef9cad4c9f1584",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-p"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "bb3f398a71f94d4fa5ef9faf40af802c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "797a4d09",
    "execution_start": 1651154444783,
    "execution_millis": 187,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 135.171875
   },
   "source": "\npairTrain, labelTrain = make_pairs_efficient(training)\npairTest, labelTest = make_pairs_efficient(validation)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Explore Dataset",
   "metadata": {
    "cell_id": "3ea8181e268143c9b78c358d60597764",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h2"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Model",
   "metadata": {
    "cell_id": "214ae5e42441496ba9a888aebc91e2ff",
    "tags": [],
    "is_collapsed": false,
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "dad70f8520b944db9c1977155cf965f3",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "936dc91c",
    "execution_start": 1651155166892,
    "execution_millis": 12,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 477.15625
   },
   "source": "def build_siamese_model_old(input_shape, embeddingDim=48):\n\n    # specify the inputs for the feature extractor network\n    inputs = Input(input_shape)\n\n    # define the first set of CONV => RELU => POOL => DROPOUT layers\n    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n    x = MaxPooling2D(pool_size=(2, 2))(x)\n    x = Dropout(0.3)(x)\n\n    # second set of CONV => RELU => POOL => DROPOUT layers\n    x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n    x = MaxPooling2D(pool_size=2)(x)\n    x = Dropout(0.3)(x)\n\n    # prepare the final outputs\n    pooledOutput = GlobalAveragePooling2D()(x)\n    outputs = Dense(embeddingDim)(pooledOutput)\n    # build the model\n    model = Model(inputs, outputs)\n    # return the model to the calling function\n    return model\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "ea1f22562a964ca79f3844a701fef2b4",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 426.15625
   },
   "source": "def build_siamese_model(input_shape, embeddingDim):\n    \n\n    inputs = keras.layers.Input(input_shape)\n    x = keras.layers.Rescaling(scale=1.0 / 255)(inputs)\n    x = keras.layers.Conv2D(64, 3, activation=\"relu\")(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Conv2D(128, 3, activation=\"relu\")(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.MaxPool2D((4, 4))(x)\n    x = keras.layers.Conv2D(256, 3, activation=\"relu\")(x)\n    x = keras.layers.BatchNormalization()(x)\n    x = keras.layers.Conv2D(256, 3, activation=\"relu\")(x)\n    x = keras.layers.GlobalMaxPool2D()(x)\n    outputs = tfsim.layers.MetricEmbedding(embeddingDim)(x)\n\n    # building model\n    model = tfsim.models.SimilarityModel(inputs, outputs)\n    model.summary()\n\n    return model",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "11670ff0696c4916b18346b0eb4fb4e1",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3b5d52e0",
    "execution_start": 1651155169734,
    "execution_millis": 9,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 207.15625
   },
   "source": "def eucledian_distance(vectors):\n\n    (fa, fb) = vectors\n\n    sum_squared = K.sum(K.square(fa-fb), axis= 1, keepdims = True)\n\n    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "4205f139bbbf414aa8201d8b55fc580f",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4f2eb296",
    "execution_start": 1651155172048,
    "execution_millis": 263,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 171.15625
   },
   "source": "f_ext = build_siamese_model((128,128,3))\nimgA = Input(shape=(128,128,3)) # non so cosa faccia sta cosa\nimgB = Input(shape=(128,128,3))\n\nfeatsA = f_ext(imgA)\nfeatsB = f_ext(imgB)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "737a779960ab4cb3bc3f89f2034f2da1",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1b678a51",
    "execution_start": 1651155174530,
    "execution_millis": 59,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 117.15625
   },
   "source": "distance = Lambda(eucledian_distance)([featsA, featsB])\noutputs = Dense(1, activation=\"sigmoid\")(distance)\nmodel = Model(inputs=[imgA, imgB], outputs=outputs)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "74135c8f03894173a904ad9ab7615698",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "239b5be6",
    "execution_start": 1651155176462,
    "execution_millis": 12,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99.15625
   },
   "source": "tr_imgs, tr_labels = zip(*training)\nval_imgs, tr_labels = zip(*validation)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "e64f16d292484b5db6b17e7b7c4d9c36",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6803617f",
    "execution_start": 1651155407233,
    "execution_millis": 2501919,
    "is_output_hidden": false,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 802.375
   },
   "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimgs1 = np.array([tr_imgs[index] for index in pairTrain[:, 0] ])\nimgs2 = np.array([tr_imgs[index] for index in pairTrain[:, 1] ])\n\nval1 = [val_imgs[index] for index in pairTest[:, 0] ]\nval2 = [val_imgs[index] for index in pairTest[:, 1] ]\n\ndatagen = ImageDataGenerator(\n        rotation_range=10, # rotation\n        width_shift_range=0.2, # horizontal shift\n        height_shift_range=0.2, # vertical shift\n        zoom_range=0.2, # zoom\n        horizontal_flip=True, # horizontal flip\n        brightness_range=[0.2,1.2]) # brightness\n\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",metrics=[\"accuracy\"])\n\nhistory = model.fit_generator(\n\tdatagen.flow([imgs1, imgs2], labelTrain[:], batch_size=32),\n\t#validation_data=([val1, val2], labelTest[:]), \n\tepochs=10)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\nEpoch 1/10\n136/136 [==============================] - 449s 3s/step - loss: 1.6201 - accuracy: 0.5030\nEpoch 2/10\n136/136 [==============================] - 444s 3s/step - loss: 0.6978 - accuracy: 0.5025\nEpoch 3/10\n136/136 [==============================] - 451s 3s/step - loss: 0.6953 - accuracy: 0.4892\nEpoch 4/10\n136/136 [==============================] - 423s 3s/step - loss: 0.6941 - accuracy: 0.5009\nEpoch 5/10\n136/136 [==============================] - 329s 2s/step - loss: 0.6939 - accuracy: 0.4922\nEpoch 6/10\n 90/136 [==================>...........] - ETA: 1:52 - loss: 0.6942 - accuracy: 0.5021",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9c7ecf0712fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelTrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#validation_data=([val1, val2], labelTest[:]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \tepochs=10)\n\u001b[0m",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2221\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "22a1d4926ccb4d6bad2dae91d348d467",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b987750c",
    "execution_start": 1651159104776,
    "execution_millis": 111,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 208.25
   },
   "source": "\n\npreds = model.predict([np.expand_dims(val_imgs[11], axis=0), np.expand_dims(val_imgs[11], axis=0)])\nproba = preds[0][0]\n\nproba",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 46,
     "data": {
      "text/plain": "0.4775884"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "a06b484a05db4ee0ad4d85ef19753583",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f5d5fb0e",
    "execution_start": 1651159076228,
    "execution_millis": 576,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 118.25
   },
   "source": "proba",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 43,
     "data": {
      "text/plain": "0.4775884"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "89b5b3a488a84c37a87cf19b318fa257",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4e6a3b95",
    "execution_start": 1651158173724,
    "execution_millis": 533,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 533.484375
   },
   "source": "model.summary()",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n model (Functional)             (None, 48)           20400       ['input_2[0][0]',                \n                                                                  'input_3[0][0]']                \n                                                                                                  \n lambda (Lambda)                (None, 1)            0           ['model[0][0]',                  \n                                                                  'model[1][0]']                  \n                                                                                                  \n dense_1 (Dense)                (None, 1)            2           ['lambda[0][0]']                 \n                                                                                                  \n==================================================================================================\nTotal params: 20,402\nTrainable params: 20,402\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "42affaf1b9ba4913942015070527ce1f",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "c512d106",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81.15625
   },
   "source": "len(training  )",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=93aceac2-8452-469e-8b02-c16d0438aa9c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {},
  "deepnote_notebook_id": "d19bd9ae-6b70-49d7-be77-bce748272417",
  "deepnote_execution_queue": []
 }
}